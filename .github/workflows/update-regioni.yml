name: Update ISTAT Regioni

on:
  schedule:
    - cron: "0 3 1 */3 *"   # Ogni 3 mesi (1Â° giorno, ore 03:00 UTC)
  workflow_dispatch:        # Permette avvio manuale

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests lxml

      - name: Generate regioni.json
        run: |
          python <<EOF
import requests
from lxml import etree
import json

# ===============================
# CONFIGURAZIONE REGIONI
# ===============================

mappa = {
    'ITC1': '01','ITC2': '02','ITC3': '07','ITC4': '03',
    'ITH1': '04','ITH3': '05','ITH4': '06','ITH5': '08',
    'ITI1': '09','ITI2': '10','ITI3': '11','ITI4': '12',
    'ITF1': '13','ITF2': '14','ITF3': '15','ITF4': '16',
    'ITF5': '17','ITF6': '18','ITG1': '19','ITG2': '20'
}

# Dividiamo in 2 gruppi per evitare limiti SDMX
groups = [
    ['ITC1','ITC2','ITC3','ITC4','ITH1','ITH3','ITH4','ITH5','ITI1','ITI2'],
    ['ITI3','ITI4','ITF1','ITF2','ITF3','ITF4','ITF5','ITF6','ITG1','ITG2']
]

# ===============================
# FUNZIONE FETCH SDMX
# ===============================

def fetch_group(nuts_group):

    nuts_list = "+".join(nuts_group)

    url = (
        "https://esploradati.istat.it/SDMXWS/rest/data/"
        "IT1,22_289_DF_DCIS_POPRES1_1,1.0/"
        f"A.{nuts_list}.JAN.9..99/ALL/"
        "?detail=dataonly"
        "&startPeriod=2020-01-01"
        "&endPeriod=2025-12-31"
        "&dimensionAtObservation=TIME_PERIOD"
    )

    response = requests.get(url, timeout=120)
    response.raise_for_status()

    root = etree.fromstring(response.content)

    ns = {
        "g": "http://www.sdmx.org/resources/sdmxml/schemas/v2_1/data/generic"
    }

    dataset = {}

    series_nodes = root.xpath("//g:Series", namespaces=ns)

    for series in series_nodes:

        ref_area = series.xpath("./g:SeriesKey/g:Value[@id='REF_AREA']/@value", namespaces=ns)
        age = series.xpath("./g:SeriesKey/g:Value[@id='AGE']/@value", namespaces=ns)

        if not ref_area or not age:
            continue

        if age[0] != "TOTAL":
            continue

        nuts = ref_area[0]

        if nuts not in mappa:
            continue

        istat = mappa[nuts]

        observations = series.xpath("./g:Obs", namespaces=ns)

        serie = {}

        for obs in observations:
            anno = obs.xpath("./g:ObsDimension/@value", namespaces=ns)[0]
            val  = int(obs.xpath("./g:ObsValue/@value", namespaces=ns)[0])
            serie[anno] = val

        serie = dict(sorted(serie.items()))

        dataset[istat] = {
            "popolazione": {
                "attuale": list(serie.values())[-1] if serie else None,
                "serie": serie
            },
            "pil": None,
            "superficie": None,
            "imprese": None
        }

    return dataset

# ===============================
# COSTRUZIONE DATASET COMPLETO
# ===============================

final_dataset = {}

for group in groups:
    group_data = fetch_group(group)
    final_dataset.update(group_data)

# Ordiniamo per codice ISTAT
final_dataset = dict(sorted(final_dataset.items()))

with open("regioni.json", "w", encoding="utf-8") as f:
    json.dump(final_dataset, f, ensure_ascii=False, indent=2)

print("regioni.json generato - struttura scalabile")
          EOF
    
      - name: Commit and push if changed
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add regioni.json
          git diff --quiet && git diff --staged --quiet || git commit -m "Aggiornamento automatico regioni.json"
          git push
